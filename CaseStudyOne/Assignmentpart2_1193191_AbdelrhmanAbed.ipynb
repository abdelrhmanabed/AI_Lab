{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 1: Import Libraries**"
      ],
      "metadata": {
        "id": "rzu4lUHuJlDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import time\n"
      ],
      "metadata": {
        "id": "urd_R6AOAcl6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 2: Load and Explore Data**\n"
      ],
      "metadata": {
        "id": "XS42UB_1JhwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data.csv\")\n",
        "for col in df.select_dtypes(include=['number']).columns:\n",
        "    df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "X = df.drop(\"Target\", axis=1)\n",
        "y = df[\"Target\"]\n",
        "\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numerical_cols = X.select_dtypes(include=['number']).columns\n",
        "\n",
        "\n",
        "numerical_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "F2kgt6N3Ae1e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.Evaluate Model**"
      ],
      "metadata": {
        "id": "eVQyh1djJbG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tracemalloc  # For memory usage tracking\n",
        "\n",
        "def evaluate_model_with_memory(model, X_train, X_test, y_train, y_test):\n",
        "    tracemalloc.start()  # Start tracking memory usage\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    end_time = time.time()\n",
        "    current, peak_memory = tracemalloc.get_traced_memory()  # Memory usage in bytes\n",
        "    tracemalloc.stop()  # Stop memory tracking\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred, average=\"weighted\"),\n",
        "        \"Recall\": recall_score(y_test, y_pred, average=\"weighted\"),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred, average=\"weighted\"),\n",
        "        \"Execution Time (s)\": end_time - start_time,\n",
        "        \"Memory Used (KB)\": peak_memory / 1024  # Convert to KB\n",
        "    }\n",
        "    return metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "FXd90KQUAfcy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.Random Forest**"
      ],
      "metadata": {
        "id": "RsId4bRLJSqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest = RandomizedSearchCV(\n",
        "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    param_distributions={\"n_estimators\": [50, 100], \"max_depth\": [None, 10]},\n",
        "    n_iter=4,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor), ('model', random_forest)])\n",
        "rf_metrics = evaluate_model_with_memory(pipeline_rf, X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(\"Random Forest Metrics:\\n\", rf_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvdK7BOyAhsk",
        "outputId": "6b83479d-67a7-4534-8d9c-7a31e72d40f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Metrics:\n",
            " {'Accuracy': 0.8951428571428571, 'Precision': 0.8991633816467566, 'Recall': 0.8951428571428571, 'F1-Score': 0.8939176611006053, 'Execution Time (s)': 58.67762207984924, 'Memory Used (KB)': 64147.40234375}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.MLP**"
      ],
      "metadata": {
        "id": "6FH55YvzJKyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = RandomizedSearchCV(\n",
        "    MLPClassifier(random_state=42, max_iter=300),\n",
        "    param_distributions={\"hidden_layer_sizes\": [(50,), (100,)], \"activation\": [\"relu\", \"tanh\"], \"learning_rate_init\": [0.001, 0.01]},\n",
        "    n_iter=4,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "pipeline_mlp = Pipeline(steps=[('preprocessor', preprocessor), ('model', mlp_model)])\n",
        "mlp_metrics = evaluate_model_with_memory(pipeline_mlp, X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(\"MLP Metrics:\\n\", mlp_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S5g7WIfAqv7",
        "outputId": "1126aebf-3b79-4c73-8bfd-2e4c5e9d0b61"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Metrics:\n",
            " {'Accuracy': 0.8681428571428571, 'Precision': 0.8700859439264315, 'Recall': 0.8681428571428571, 'F1-Score': 0.8661660132585184, 'Execution Time (s)': 488.0951340198517, 'Memory Used (KB)': 64218.064453125}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.SVM**"
      ],
      "metadata": {
        "id": "Rf8JrIl2JD-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = RandomizedSearchCV(\n",
        "    SVC(probability=True, random_state=42),\n",
        "    param_distributions={\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]},\n",
        "    n_iter=4,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "pipeline_svm = Pipeline(steps=[('preprocessor', preprocessor), ('model', svm_model)])\n",
        "svm_metrics = evaluate_model_with_memory(pipeline_svm, X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(\"SVM Metrics:\\n\", svm_metrics)\n"
      ],
      "metadata": {
        "id": "Gy9MthKXAnE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.Combine results from all models**\n"
      ],
      "metadata": {
        "id": "CDkWROgsI8s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    \"Random Forest\": rf_metrics,\n",
        "    \"SVM\": svm_metrics,\n",
        "    \"MLP\": mlp_metrics\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "print(\"\\nComparison of Models:\")\n",
        "print(results_df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IQb0eG5gAuGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "voB_k9-6LY1I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}